{"cells":[{"cell_type":"markdown","metadata":{"id":"WBjUTvAUxGQT"},"source":["\n","############################################################################\n","\n","This a shared directory. Please add a shortcut to you MyDrive folder to make it work. Make sure it is the whole folder !!!\n","\n","############################################################################\n"],"id":"WBjUTvAUxGQT"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23521,"status":"ok","timestamp":1649089970798,"user":{"displayName":"Hassan Alnamer","userId":"08461140569716493209"},"user_tz":420},"id":"KnSSeipAp59z","outputId":"be5ac1b0-d138-4dfc-d974-b7d55210a656"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_io\n","  Downloading tensorflow_io-0.24.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n","\u001b[K     |████████████████████████████████| 23.4 MB 6.4 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.24.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_io) (0.24.0)\n","Installing collected packages: tensorflow-io\n","Successfully installed tensorflow-io-0.24.0\n","Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.16.1\n"]}],"source":["!pip install tensorflow_io\n","!pip install tensorflow_addons"],"id":"KnSSeipAp59z"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21663,"status":"ok","timestamp":1649089992455,"user":{"displayName":"Hassan Alnamer","userId":"08461140569716493209"},"user_tz":420},"id":"BNXrtw_PrRwQ","outputId":"e73dc70e-b03f-4066-d3e2-a27a163c1019"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive\n","Mounted at /content/drive\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive # import drive from google colab\n","\n","ROOT = \"/content/drive\"     # default location for the drive\n","print(ROOT)                 # print content of ROOT (Optional)\n","\n","drive.mount(ROOT)      \n","cwd = f'{ROOT}/MyDrive/autoencoder'"],"id":"BNXrtw_PrRwQ"},{"cell_type":"code","execution_count":2,"metadata":{"id":"f3a0c653","executionInfo":{"status":"ok","timestamp":1649102530859,"user_tz":420,"elapsed":8206,"user":{"displayName":"Hassan Alnamer","userId":"08461140569716493209"}}},"outputs":[],"source":["'''\n","This file uses the experimental tool published by tensorflow to load\n","tiff files\n","\n","I expect the subset ot look like:\n","foldername:\n","        label1:\n","            img1\n","            img2\n","            img3 \n","            ...\n","        ...\n","\n","I produce a list of all images in all files without labels:\n","[ tensor(img1), tensor(img2), ...]\n","\n","'''\n","\n","import pandas as pd\n","import tensorflow as tf\n","import numpy as np\n","import json\n","import tensorflow_io as tfio\n","import os\n","#import tf.image.ResizeMethod as ResizeMethod\n","\n","\n","class process_tiff_img_set():\n","    def __init__(self, ds_folder_name):\n","        \n","        self.folder = ds_folder_name\n","        self.df =  self.create_df()\n","\n","    def pad_img(self, img):\n","      \n","      image_stack = img\n","        \n","      img_shape = tf.shape(image_stack)\n","      \n","      extra_top = int((8000-img_shape[0]))\n","      extra_bottom = 0\n","\n","      \n","      extra_right = int((2000-img_shape[1]))\n","      extra_left = 0\n","      padded = np.pad(image_stack, ((extra_top, extra_bottom), (extra_left, extra_right), (0, 0)), mode='constant', constant_values=0) \n","      return padded\n","\n","    def decode_img(self, img):\n","        #print(f'decoding ... ')\n","        img = tfio.experimental.image.decode_tiff(img, index=0, name=None)[:, :, :3]\n","        #img_np = np.pad(img, (256, 256, 3))\n","        #tensor_img = tf.convert_to_tensor(a)   \n","        #print(tf.size(img))\n","        #print(tf.shape(img))\n","        # resize the image to the desired size\n","        img = self.pad_img(img)\n","        return img\n","        '''tf.image.resize_with_pad(\n","                img,\n","                256,\n","                256,\n","                method=tf.image.ResizeMethod.BILINEAR,\n","                antialias=False\n","            )'''\n","\n","\n","    def process_path(self, file_path):\n","\n","        # load the raw data from the file as a string\n","        #print(f'reading {file_path}')\n","        img = tf.io.read_file(file_path)\n","        img = self.decode_img(img)\n","\n","        return img\n","\n","    def create_df(self):\n","        '''\n","        This function creates a dataframe with all labels and \n","        images file paths\n","        I will use later to store numpy arrays\n","        '''\n","        cwd = f'/content/drive/MyDrive/autoencoder'\n","        ds = []\n","        DS_PATH = os.path.join(cwd, self.folder)\n","        labels = os.listdir(DS_PATH)\n","        for lbl in labels:\n","            cwd = os.path.join(DS_PATH, lbl)\n","            if(not os.path.isdir(cwd)):\n","                print(f'{cwd} is not a directory. Will not be in dict')\n","                continue\n","            images = os.listdir(cwd)\n","            for img in images:\n","                #convert to numpy matrix here\n","                if(img.split('.')[1] != 'tif'):\n","                    print(f'{img} is not a tiff file. Will not be in dict')\n","                    continue\n","                path = os.path.join(cwd, img)\n","\n","                #changes\n","                img_np = self.process_path(path) #Tensor \n","                ds.append(img_np)\n","\n","        \n","        return ds\n","  \n","    def get_tensor(self):\n","        return (self.df)\n","\n","\n","    def __str__(self):\n","        obj_str = \"\"\n","        for i, obj in enumerate(self.df):\n","            obj_str += f'{i}: {str(obj)},\\n'\n","        return f'<process_tiff_img_set>:\\n{obj_str}'\n","\n","\n","\n"],"id":"f3a0c653"},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2053,"status":"ok","timestamp":1649089999887,"user":{"displayName":"Hassan Alnamer","userId":"08461140569716493209"},"user_tz":420},"id":"pMkfIDjGmc1R","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8e69bafe-70be-4ee1-f729-9bbd5134f2c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 1s 0us/step\n","58900480/58889256 [==============================] - 1s 0us/step\n"]}],"source":["'''\n","I found this model in Kaggle\n","It uses VGG16 model like I found in the paper\n","I attached a single Dense layer with a Relu activation just to output the alpha\n","value\n","'''\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import os\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.losses import *\n","from keras.models import Model\n","\n","\n","IMAGE_SIZE = [256, 256]\n","\n","vgg = VGG16(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False) \n","\n","# this will exclude the initial layers from training phase as there are already been trained.\n","for layer in vgg.layers:\n","    layer.trainable = False\n","\n","\n","x = Flatten()(vgg.output)\n","#x = Dense(128, activation = 'relu')(x)   # we can add a new fully connected layer but it will increase the execution time.\n","x = Dense(1, activation = 'relu')(x)  # adding the output layer with softmax function as this is a multi label classification problem.\n","\n","vgg16 = Model(inputs = vgg.input, outputs = x)\n","\n","vgg16.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","      "],"id":"pMkfIDjGmc1R"},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import os\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras.losses import *\n","from keras.models import Model\n","class Autoencoder(Model):\n","  def __init__(self, latent_dim):\n","    super(Autoencoder, self).__init__()\n","    self.latent_dim = latent_dim   \n","    self.encoder = tf.keras.Sequential([\n","      #layers.Flatten(),\n","      layers.Dense(latent_dim, activation='sigmoid'),\n","    ])\n","    self.decoder = tf.keras.Sequential([\n","      layers.Dense(4, activation='sigmoid'),\n","      #layers.Reshape((256))\n","    ])\n","\n","  def call(self, x):\n","    encoded = self.encoder(x)\n","    \n","    decoded = self.decoder(encoded)\n","    return decoded"],"metadata":{"id":"YI0oxH4CI7Pd","executionInfo":{"status":"ok","timestamp":1649102540353,"user_tz":420,"elapsed":282,"user":{"displayName":"Hassan Alnamer","userId":"08461140569716493209"}}},"id":"YI0oxH4CI7Pd","execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s4rW4IUhrzIX","outputId":"50ab402e-7aee-42ea-8e2b-a26154bed951","executionInfo":{"status":"ok","timestamp":1649102563230,"user_tz":420,"elapsed":20638,"user":{"displayName":"Hassan Alnamer","userId":"08461140569716493209"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/autoencoder/subset1/.DS_Store is not a directory. Will not be in dict\n"]}],"source":["x_train = process_tiff_img_set(\"subset1\")\n","x_train = x_train.get_tensor()\n","\n","\n","x_test = process_tiff_img_set('subset2')\n","x_test = x_test.get_tensor()"],"id":"s4rW4IUhrzIX"},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":866,"status":"error","timestamp":1649102658014,"user":{"displayName":"Hassan Alnamer","userId":"08461140569716493209"},"user_tz":420},"id":"102b68fb","outputId":"9fbafe22-40e8-4217-b6c1-72c006a7041f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:1' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:2' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:3' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:4' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:5' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:6' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:7' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:8' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:9' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:10' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:11' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:12' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:13' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:14' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:15' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:16' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:17' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:18' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:19' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:20' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:21' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:22' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:23' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:24' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:25' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:26' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:27' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:28' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:29' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:30' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:31' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:32' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:33' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:34' shape=(2, 2000, 3) dtype=uint8>). Consider rewriting this model with the Functional API.\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-c94677104f0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 verbose=1)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"autoencoder_3\" (type Autoencoder).\n    \n    in user code:\n    \n        File \"<ipython-input-3-843fb651c64b>\", line 24, in call  *\n            encoded = self.encoder(x)\n        File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n            raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n    \n        ValueError: Exception encountered when calling layer \"sequential_6\" (type Sequential).\n        \n        Layer \"dense_6\" expects 1 input(s), but it received 35 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:1' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:2' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:3' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:4' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:5' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:6' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:7' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:8' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:9' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:10' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:11' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:12' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:13' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:14' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:15' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:16' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:17' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:18' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:19' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:20' shape=(2, 2000, 3) dtype=uint8>, <tf.Tensor 'IteratorGetNext:21' shape=(2, 2000...\n        \n        Call arguments received:\n          • inputs=('tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.T...\n          • training=True\n          • mask=None\n    \n    \n    Call arguments received:\n      • x=('tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(shape=(2, 2000, 3), dtype=uint8)', 'tf.Tensor(sha...\n"]}],"source":["import os\n","import pandas as pd\n","\n","#x_train & x_test are a list of tensors\n","#each tensor is 256x256, dtype=float32\n","#\n","#print to get more insight\n","#print(f'x_train: {x_train}')\n","#print(f'x_test: {x_test}')\n","\n","\n","\n","\n","autoencoder = Autoencoder(64)\n","autoencoder.compile(optimizer='rmsprop', loss=tf.keras.losses.BinaryCrossentropy)\n","\n","history = autoencoder.fit(x_train, x_train,\n","                epochs=10,\n","                batch_size = 2,\n","                shuffle=True,\n","                \n","                verbose=1)\n"],"id":"102b68fb"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":499},"executionInfo":{"elapsed":433,"status":"error","timestamp":1648160370028,"user":{"displayName":"Hassan Alnamer","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08461140569716493209"},"user_tz":420},"id":"W05J5bchuWE9","outputId":"9ed0e2f5-ddf2-4a64-cbbf-be2a1b724f91"},"outputs":[{"ename":"KeyError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-96-6a6a11249900>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Plot history: MAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Loss (training data)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Loss (validation data)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AutoEncoder loss function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MAE value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'val_loss'"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYYAAAEDCAYAAAAx/aOOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3RU9bn/8feTGyEBAoRwSyIJJEGDF9SIeAdCEFsFT6sVWluttlYLyq0XPOe3en7Hs85vHVsFUUGloqVHKyLFlmNbJYAieAEConIxySTcEm4h3C+5P78/ZlMncSADJNmZmee1FsuZ7/5+9372CPOZ794ze4uqYowxxpwW4XYBxhhj2hcLBmOMMY1YMBhjjGnEgsEYY0wjFgzGGGMasWAwxhjTSNgEg4g8KiJfichmEfntGfqMFpFCEfGIyHSf9j+IyDYR2ej8Gey0/9KnbZOI1ItId59xkSLymYi842dbz4rI8QDqHisiXzjbKBCRG8/vFTDGmMBEuV1ASxORYcD9qnq/T9twYCxwhapWi0hPP+MigdlAHlAGrBORJaq6xenyS1Vd5DtGVX8H/M4ZfwcwRVUP+nSZBGwFujTZVg7QLcBdWg4sUVUVkcuBhcDFAY41xphzFi4zhkeA/1bVagBV3e+nzxDAo6qlqloDLMAbJoEaD7xx+omIpADfBl727eQE0O+AXzVpTxKRP4vIOufPDU6tx/XrXyHGA/aLRGNMqwqXYMgCbhKRNSKyUkSu8dMnGdjl87zMaTvtv5xDOjNFpIPvQBGJA0YDf/Zpfgbvm39Dk+1MxDsD2NOkfRYwU1WvAb6LT6CIyL+IyFfA34AHmtlXY4y5ICFzKElE1gAdgE5AdxHZ6Cz6Nd797A4MBa4BFopIfw38eiCPA3uBGGCus84nfJbfAXx0+jCSiNwO7FfV9c6hrdM19gXuBobxTSOBbBE5/byLiHRyZgxvA2+LyM3Afzp9jTGmVYRMMKjqtXDGcwxTgMVOEKwVkQagB1Dhs4pyINXneYrThs+n+2oReRX4RZPNj8PnMBJwAzBGRL4FxOJ9k3/N6ZMBeJwAiBMRj6pm4J29DVXVqrPs44ci0l9EeqjqgeZeE2OMOR/hcijpL8BwABHJwvvJv+kb6zogU0TSRSQG75v9EmdMH+e/AtwJbDo9SEQSgFuAv55uU9XHVTVFVdOc9axQ1XtV9W+q2ltV05xlJ51QAFgKPOqz3tPffMpwtouIXIV3VlR54S+JMcb4FzIzhma8ArwiIpuAGuA+51s+fYGXVfVbqlonIhOB94BI4BVV3eyMf11EkgABNgIP+6z7X4ClqnriAmt8DJgtIl/g/f/yobOd7wI/EpFa4BRwzzkcAjPGmHMm9h5jjDHGV7gcSjLGGBOgkDiU1KNHD01LS3O7DGOMCSrr168/oKpJTdtDIhjS0tIoKChwuwxjjAkqIrLDX7sdSjLGGNOIBYMxxphGLBiMMcY0YsFgjDGmEQsGY4wxjVgwGGOMacSCwRhjTCMWDOaf/v7lHkormr3bqDEmxFkwGAC27jnKz1/fwLS3Pseun2VMeLNgMADMyC8C4LOdh3m/0N+dT40x4cKCwfBF2WHyt+zjsREZXNQ9jqeXFtmswZgwFlAwiMhoESkUEY+ITPezvIOIvOksXyMiaT7LHnfaC0XkVp/2KSKyWUQ2icgbIhLrtL/u9N0kIq+ISPSF76Y5m6eXFtE1Lpqf3tyfx3Iz2bz7KO9t3ut2WcYYlzQbDCISCcwGbgOygfEikt2k24PAIeduZDOBJ52x2XjvYDYIGA3MEZFIEUnGe2OaHFW9FO+NccY563oduBi4DOgI/OSC9tCc1fodB1lZVMHDtwygc2w0dw7uS/+keGbmF9PQYLMGY8JRIDOGIYBHVUtVtQZYAIxt0mcsMN95vAjIdW5HORZYoKrVqroN8DjrA++VXTuKSBQQB+wGUNW/qwNYi/fey6aVPL20iB6dYvjRdf0AiIqMYPLILAr3HeOdL/c0M9oYE4oCCYZkYJfP8zKnzW8fVa0DjgCJZxqrquXAU8BOYA9wRFWX+q7QOYT0Q+Bdf0WJyEMiUiAiBRUVFQHshmnq45IDfFxSySPDMoiL+foK7Ldf1oeBvTrzTH4RdfUNLlZojHGDKyefRaQb3tlEOtAXiBeRe5t0mwN8qKqr/K1DVeeqao6q5iQlfeM+E6YZqsqMpUX07hLLD669qNGyiAhhSl4WpQdO8JeNu12q0BjjlkCCoRxI9Xme4rT57eMcGkoAKs8ydiSwTVUrVLUWWAxcf7qTiPw7kARMPZedMYFbWVRBwY5DTBiRQWx05DeW3zqoF5cmd2HW8iJqbdZgTFgJJBjWAZkiki4iMXhPEi9p0mcJcJ/z+C5ghXOOYAkwzvnWUjqQife8wU5gqIjEOecicoGtACLyE+BWYLyq2jtSK1BVZuQXkdy1I/fkpPrtIyJMyxvIroOneKugrI0rNMa4qdlgcM4ZTATew/vmvVBVN4vIEyIyxuk2D0gUEQ/eT/nTnbGbgYXAFrznCiaoar2qrsF7knoD8KVTx1xnXS8CvYBPRGSjiPymZXbVnLZs636+KDvCpNxMYqLO/Fdg2MAkrryoK8+tKKaqtr4NKzTGuElC4YdMOTk5avd8DkxDg/KtZ1dRVVvPsqm3EBV59s8Gq4sPcO+8NfzfO7K5/4b0NqrSGNMWRGS9quY0bbdfPoeZf2zay1d7jzF5ZFazoQBwQ0Yi16Z3Z/YHJZyqsVmDMeHAgiGM1DcoM5cVkdmzE3dc0TegMSLCtFEDqThWzf98ur11CzTGtAsWDGFkyeflePYfZ0peFpEREvC4IenduSmzBy+uLOV4dV0rVmiMaQ8sGMJEbX0Ds5YVc0mfLowe1Pucx08bNZCDJ2qY//H2li/OGNOuWDCEicUbytheeZKpeVlEnMNs4bTBqV3JvbgnL60s4cip2lao0BjTXlgwhIGaugaeXe7hipQERl7S87zXMyUvi6NVdcxbva0FqzPGtDcWDGHgzYJdlB8+xdRRA/H+nvD8XJqcwG2X9uaV1ds4dKKmBSs0xrQnFgwhrqq2nudXFHNNWjduzuxxweubkpfFiZo6XvqwtAWqM8a0RxYMIe71NTvZd7SaqXkXNls4LatXZ8Zc0Zf5H2+n4lh1C1RojGlvLBhC2MmaOl74wMP1AxK5bkBii613Um4m1XX1vPBBSYut0xjTflgwhLD5H+/gwPEapo3KatH19k/qxHevSuG1NTvYe6SqRddtjHGfBUOIOlZVy0sfljBsYBJX9+ve4ut/LDeThgZl9vueFl+3McZdFgwh6pXV2zl8spZpeQNbZf2p3eO455pUFqzbSdmhk62yDWOMOywYQtDhkzW8vKqUUdm9uCwlodW2M3FEBiLCc8tt1mBMKLFgCEG/X1XKseo6puS17LmFpvokdOT7Qy5i0YYyth840arbMsa0HQuGEFN5vJpXP9rO7Zf34ZI+XVp9ez8fPoDoSGHW8uJW35Yxpm1YMISYlz4spaq2nskjW3e2cFrPzrHcd10af9lYTvG+Y22yTWNM67JgCCH7j1Yx/+Pt3HllMhk9O7XZdn92ywDioiN5ZpnNGowJBQEFg4iMFpFCEfGIyHQ/yzuIyJvO8jUikuaz7HGnvVBEbvVpnyIim0Vkk4i8ISKxTnu6sw6Ps86YC9/N8DDngxLqGpRJuZltut3u8TE8cGM6f/tyD1t2H23TbRtjWl6zwSAikcBs4DYgGxgvItlNuj0IHFLVDGAm8KQzNhsYBwwCRgNzRCRSRJKBx4AcVb0UiHT64Yyd6azrkLNu04zyw6f405qd3H11Cv0S49t8+z+5sT+dY6OYkV/U5ts2xrSsQGYMQwCPqpaqag2wABjbpM9YYL7zeBGQK94L84wFFqhqtapuAzzO+gCigI4iEgXEAbudMSOcdeCs887z27Xw8vwK71dGH23j2cJpCXHRPHRTf5Zt3cfnuw67UoMxpmUEEgzJwC6f52VOm98+qloHHAESzzRWVcuBp4CdwB7giKoudcYcdtZxpm0BICIPiUiBiBRUVFQEsBuha2flSd4q2MW4Iakkd+3oWh0/vjGdbnHRNmswJsi5cvJZRLrhnU2kA32BeBG591zWoapzVTVHVXOSkpJao8ygMWt5MZERwoThGa7W0alDFA/fMoCVRRUUbD/oai3GmPMXSDCUA6k+z1OcNr99nENDCUDlWcaOBLapaoWq1gKLgeudMV2ddZxpW8ZHScVx3v6sjB8O7UevLrFul8OPrkujR6cOPL3UZg3GBKtAgmEdkOl8WygG70niJU36LAHucx7fBaxQVXXaxznfWkoHMoG1eA8hDRWROOe8Qi6w1RnzvrMOnHX+9fx3L/Q9s6yY2OhIHh42wO1SAOgYE8nPhw3gk9JKPvYccLscY8x5aDYYnOP9E4H3gK3AQlXdLCJPiMgYp9s8IFFEPMBUYLozdjOwENgCvAtMUNV6VV2D9wTzBuBLp465zrp+DUx11pXorNv4Ubj3GO98sZv7r/d+Sm8vvn/tRfTuEsvT+UV4s94YE0wkFP7h5uTkaEFBgdtltLmH/2c9H3kOsOrXw+ka175+7vHapzv4P3/ZxB9+fA3DBvZ0uxxjjB8isl5Vc5q22y+fg9Sm8iO8u3kvD96U3u5CAeB7OamkdOvIDJs1GBN0LBiC1Iz8IhI6RvPAjelul+JXTFQEj+Vm8kXZEfK37HO7HGPMObBgCELrdxxixVf7eejm/nSJjXa7nDP6zpXJpPeIZ0Z+EQ0NNmswJlhYMAShmflFJMbHcP/1aW6XclZRkRFMHpnJV3uP8fdNe9wuxxgTIAuGIPNpaSWrPQd4ZNgA4jtENT/AZbdf3pfMnp2YmV9Evc0ajAkKFgxBRFWZsbSInp07cO/Qfm6XE5DICGFqXhYlFSf460b7raIxwcCCIYis9hxg7faDTByRQWx0pNvlBOzWQb3J7tOFWcuLqa1vcLscY0wzLBiChKry1NIi+ibEcs81qc0PaEcinFnDjsqT/Hl9mdvlGGOaYcEQJFZ8tZ/Pdx3msdxMOkQFz2zhtNxLenJFaleeW+Ghuq7e7XKMMWdhwRAEGhqUGflFXNQ9ju9eneJ2OedFRJiWl0X54VMsXLer+QHGGNdYMASB9zbvZfPuo0wemUl0ZPD+L7spswdD0rrz3AoPVbU2azCmvQred5kwUd+gzFxWxICkeMYO9nvPoqAhIkwdlcX+Y9W89ukOt8sxxpyBBUM7984Xuynad5zJI7OIjBC3y7lgQ/snckNGIi98UMKJ6rrmBxhj2pwFQztWV9/AM8uKubh3Z759WR+3y2kxU/MGUnmihvmfbHe7FGOMHxYM7djbn5Wz7cAJpuRlERECs4XTru7XjeEDk3hpZSlHq2rdLscY04QFQztVU9fArOXFXJacwKjsXm6X0+Km5g3kyKlaXlm9ze1SjDFNWDC0U2+t30XZoVNMHZWF9+6noeWylARuHdSLeau2cfhkjdvlGGN8WDC0Q1W19Ty33MNVF3VlWFaS2+W0mil5WRyvqWPuh6Vul2KM8RFQMIjIaBEpFBGPiEz3s7yDiLzpLF8jImk+yx532gtF5FanbaCIbPT5c1REJjvLBovIp057gYgMaZldDR5vrN3J3qNV/GLUwJCcLZx2ce8u3H55X/7w8XYqj1e7XY4xxtFsMIhIJDAbuA3IBsaLSHaTbg8Ch1Q1A5gJPOmMzQbGAYOA0cAcEYlU1UJVHayqg4GrgZPA2866fgv8h7PsN87zsHGqpp7Z75cwtH93rs/o4XY5rW7yyEyqaut5cWWJ26UYYxyBzBiGAB5VLVXVGmABMLZJn7HAfOfxIiBXvB91xwILVLVaVbcBHmd9vnKBElU9/YsnBbo4jxOA3eeyQ8Huj59s58DxaqaNGuh2KW1iQFIn7rwymT9+soN9R6vcLscYQ2DBkAz4XtymzGnz20dV64AjQGKAY8cBb/g8nwz8TkR2AU8Bj/srSkQecg41FVRUVASwG+3f8eo6XlxZws1ZSVyT1t3tctrMpNxM6huUOe973C7FGIPLJ59FJAYYA7zl0/wIMEVVU4EpwDx/Y1V1rqrmqGpOUlJonKB9dfU2Dp2sZWpeltultKl+ifHcnZPCG2t3UX74lNvlGBP2AgmGcsD3BgApTpvfPiIShfcQUGUAY28DNqjqPp+2+4DFzuO3+Oahp5B05FQtv19VyshLejE4tavb5bS5iSMyAXh+RbHLlRhjAgmGdUCmiKQ7n/DHAUua9FmC9w0d4C5ghaqq0z7O+dZSOpAJrPUZN57Gh5HAe07hFufxCCAs3inmrSrlaFVd2M0WTkvu2pHxQ1J5q6CMHZUn3C7HmLDWbDA45wwmAu8BW4GFqrpZRJ4QkTFOt3lAooh4gKnAdGfsZmAhsAV4F5igqvUAIhIP5PH17OC0nwJPi8jnwP8DHrqwXWz/Dp6oYd7qbXzrst5k9+3S/IAQNWF4BpERwqzlYfFZwJh2KyqQTqr6d+DvTdp+4/O4Crj7DGP/C/gvP+0n8J6gbtq+Gu9XWFvd25+V8bGnsi02dVbbK09wsraeKSPDc7ZwWs8usfzoun7MW70NQQihy0NdkNTucTw6IiOkf9Ni2peAgiFUlew/wUeeA26XAcBPb+pPZq/ObpfhuodvGcBHnko+KWkf/1/cVlOvHDhezWXJCQy/uKfb5ZgwId5TAcEtJydHCwoK3C7DmBZXW9/AiKc/oGvHGJZMvMFmDaZFich6Vc1p2m7XSjKmHYuOjGBSbhZflh9h6ZZ9zQ8wpgVYMBjTzt05uC/9e8QzY2kRDQ3BP8M37Z8FgzHtXFRkBJNGZlK47xh/+3KP2+WYMGDBYEwQuOPyvgzs1ZmZy4qoq29wuxwT4iwYjAkCERHClLxMSitO8NeNYXVdSeMCCwZjgsStg3ozqG8XZi0vptZmDaYVWTAYEyREhGmjsth58CSL1pe5XY4JYRYMxgSR4QN7Mji1K88tL6a6rt7tckyIsmAwJoiICL8YNZDdR6pYsHZX8wOMOQ8WDMYEmRsyEhmS3p3Z73uoqrVZg2l5FgzGBBkRYVpeFvuPVfPapzuaH2DMObJgMCYIXds/kZsyezDngxJOVNe5XY4JMRYMxgSpqXlZHDxRwx8+3u52KSbEWDAYE6SuvKgbuRf3ZO6HpRytqnW7HBNCLBiMCWJT8rI4cqqWeau2uV2KCSEWDMYEsUuTE7jt0t68snobh07UuF2OCREBBYOIjBaRQhHxiMh0P8s7iMibzvI1IpLms+xxp71QRG512gaKyEafP0dFZLLPmEdF5CsR2Swiv73w3TQmdE3Jy+J4TR1zV5W6XYoJEc0Gg4hEArOB24BsYLyIZDfp9iBwSFUzgJnAk87YbGAcMAgYDcwRkUhVLVTVwao6GO/9nU8CbztjhgNjgStUdRDw1IXvpjGhK6tXZ+64vC9/+Gg7B45Xu12OCQGBzBiGAB5VLVXVGmAB3jduX2OB+c7jRUCueO9BOBZYoKrVqroN8Djr85ULlKjq6S9kPwL8t6pWA6jq/nPdKWPCzeSRmVTX1fPCByVul2JCQCDBkAz4/va+zGnz20dV64AjQGKAY8cBb/g8zwJucg5JrRSRa/wVJSIPiUiBiBRUVFQEsBvGhK7+SZ34zlUpvPbpDvYdrXK7HBPkXD35LCIxwBjgLZ/mKKA7MBT4JbBQ/NwBXVXnqmqOquYkJSW1Sb3GtGeTcjOpb1Bmv+9xuxQT5AIJhnIg1ed5itPmt4+IRAEJQGUAY28DNqiq713Oy4DF6rUWaAB6BFCnMWEttXsc37smlTfW7qTs0Em3yzFBLJBgWAdkiki68wl/HLCkSZ8lwH3O47uAFaqqTvs451tL6UAmsNZn3HgaH0YC+AswHEBEsoAY4EDgu2RM+Jo4PANBeH6FzRrM+Ws2GJxzBhOB94CtwEJV3SwiT4jIGKfbPCBRRDzAVGC6M3YzsBDYArwLTFDVegARiQfygMVNNvkK0F9ENuE90X2fEzLGmGb07dqR7197EW+tL2P7gRNul2OClITCe25OTo4WFBS4XYYx7cL+Y1Xc/Nv3+dalfZhxz2C3yzHtmIisV9Wcpu32y2djQkzPzrH86Lo0/rKxHM/+Y26XY4KQBYMxIehnN/enY3QkM5cVu12KCUIWDMaEoMROHfjxDen87Ys9bN1z1O1yTJCxYDAmRP30pv50jo1iZn6R26WYIGPBYEyISoiL5qc39Wfpln18UXbY7XJMELFgMCaE/fiGNLrGRTPDZg3mHFgwGBPCOsdG8/AtA/igsIL1Ow66XY4JEhYMxoS4H13Xjx6dYnh6qc0aTGAsGIwJcXExUfx8WAYfl1TycYldXcY0z4LBmDDw/WsvoneXWGYsLSIUrnZgWpcFgzFhIDY6kgkjMijYcYgPi23WYM7OgsGYMHFPTirJXTvy9NJCmzWYs7JgMCZMxERFMCk3ky/KjrBsq90x15yZBYMxYeQ7VyWTlhjHjPwiGhps1mD8s2AwJoxERUYweWQWW/cc5R+b9rpdjmmnLBiMCTN3XNGXzJ6dmLmsiHqbNRg/LBiMCTOREcKUvCw8+4/zv5/vdrsc0w5ZMBgThkYP6s0lfbrwzLIi6uob3C7HtDMBBYOIjBaRQhHxiMh0P8s7iMibzvI1IpLms+xxp71QRG512gaKyEafP0dFZHKTdU4TERWRHhe2i8aYpiIihKl5WWyvPMniDeVul2PamWaDQUQigdnAbUA2MF5Espt0exA4pKoZwEzgSWdsNjAOGASMBuaISKSqFqrqYFUdDFwNnATe9tlmKjAK2HmB+2eMOYORl/TkipQEZi0vpqbOZg3ma4HMGIYAHlUtVdUaYAEwtkmfscB85/EiIFdExGlfoKrVqroN8Djr85ULlKjqDp+2mcCvADszZkwrERGmjhpI+eFTvFmwy+1yTDsSSDAkA75/a8qcNr99VLUOOAIkBjh2HPDG6SciMhYoV9XPz1aUiDwkIgUiUlBRURHAbhhjmro5swfXpHXj+RXFVNXWu12OaSdcPfksIjHAGOAt53kc8K/Ab5obq6pzVTVHVXOSkpJat1BjQpSIMDVvIPuOVvP6Gjtya7wCCYZyINXneYrT5rePiEQBCUBlAGNvAzao6j7n+QAgHfhcRLY7/TeISO9AdsYYc+6uG5DI9QMSeeEDDydr6twux7QDgQTDOiBTRNKdT/jjgCVN+iwB7nMe3wWsUO9VupYA45xvLaUDmcBan3Hj8TmMpKpfqmpPVU1T1TS8h56uUlX7iaYxrWjaqCwOHK9h/sc7mu9sQl6zweCcM5gIvAdsBRaq6mYReUJExjjd5gGJIuIBpgLTnbGbgYXAFuBdYIKq1gOISDyQByxu2V0yxpyrq/t1Z9jAJF76sIRjVbVul2NcJqFw+d2cnBwtKChwuwxjgtqXZUe44/nVTM3L4rHcTLfLMW1ARNarak7TdvvlszEGgMtSEhiV3YvfryrlyEmbNYQzCwZjzD9NycviWFUdv19V6nYpxkUWDMaYf7qkTxduv7wPr3y0jcrj1W6XY1xiwWCMaWTyyCyqaut56UObNYQrCwZjTCMZPTtx55XJ/PGT7ew/WuV2OcYFFgzGmG+YlJtJbb0y54MSt0sxLrBgMMZ8Q7/EeO6+OoU/rdnJ7sOn3C7HtDELBmOMX486v2V4/n2Py5WYtmbBYIzxK7lrR8YNSWXhul3srDzpdjmmDVkwGGPOaMLwDCIjhGdXFLtdimlDFgzGmDPq1SWWHw7tx+INZZRUHHe7HNNGotwuwBjTvj08bAB/WruTn8wvIKVbR7fL4e6cVMZc0dftMlxXcayan/yxgH+/I5urLurWouu2YDDGnFWPTh34t29fwqL1ZRyvdvd+DXsOV/Gbv25i+MAkOsdGu1qL2174oIQvyw7TtWPLvw4WDMaYZv3g2n784Np+bpfxzyvAvrJ6O5NGhu8VYPceqeK1NTv47lUp9E/q1OLrt3MMxpigcVlKArcO6sXLq0o5fLLG7XJc8/z7xTQ0aKtdHt2CwRgTVKbkZXG8JnyvAFt26CRvrtvFPdekkto9rlW2YcFgjAkqF/fuwrcv68OrH20PyyvAPrfcg4gwcURGq23DgsEYE3ROXwH2xZXhdS2n7QdOsGhDGd8fchF9ElrvG2IBBYOIjBaRQhHxiMh0P8s7iMibzvI1IpLms+xxp71QRG512gaKyEafP0dFZLKz7Hci8pWIfCEib4tI15bZVWNMqPj6CrA7wuoKsLOWFxMdKfx8+IBW3U6zwSAikcBs4DYgGxgvItlNuj0IHFLVDGAm8KQzNhsYBwwCRgNzRCRSVQtVdbCqDgauBk4CbzvrygcuVdXLgSLg8QvcR2NMCJqUm0l9gzI7TK7lVLzvGH/ZWM5916XRs3Nsq24rkBnDEMCjqqWqWgMsAMY26TMWmO88XgTkiog47QtUtVpVtwEeZ32+coESVd0BoKpLVfX0l6U/BVLOdaeMMaGvX2I8d+ek8MbaXZSHwRVgn1lWTFx0JD+7pXVnCxBYMCQDu3yelzltfvs4b+pHgMQAx44D3jjDth8A/uFvgYg8JCIFIlJQUVERwG4YY0LNxBHOFWBD/FpOW3Yf5W9f7uGBG9PpHh/T6ttz9eSziMQAY4C3/Cz7N6AOeN3fWFWdq6o5qpqTlJTUuoUaY9ql5K4dGT8klbcKykL6CrAz8ovoHBvFT27s3ybbCyQYyoFUn+cpTpvfPiISBSQAlQGMvQ3YoKr7fFcmIvcDtwM/UFUNoEZjTJg6fQXYWctDc9bw+a7DLNu6j4du6k9CXNtcBiSQYFgHZIpIuvMJfxywpEmfJcB9zuO7gBXOG/oSYJzzraV0IBNY6zNuPE0OI4nIaOBXwBhVDd2PAMaYFtGzSyw/uq4fb39Whmd/6F0BdkZ+Ed3iovnxjeltts1mg8E5ZzAReA/YCixU1c0i8oSIjHG6zQMSRcQDTAWmO2M3AwuBLcC7wARVrQcQkXggD1jcZJPPA52BfOerrC9e4D4aY0Lcw7cMIDY6MuRmDQXbD7KyqIKf3TKATh3a7tJ2EgpHanJycrSgoMDtMowxLvrtu9+l13UAAA47SURBVF8x54MS3p18Exf37uJ2OS1i/NxPKd5/nA9/NYy4mJYPBhFZr6o5Tdvtl8/GmJDw0M396dwhipn5RW6X0iI+9hzgk9JKfj5sQKuEwtlYMBhjQkLXuBgevCmd9zbv48uyI26Xc0FUlafzi+jdJZbvX3tRm2/fgsEYEzIeuDGdrnHRzMgvdLuUC7KyqIL1Ow4xcUQGsdGRbb59CwZjTMjoEhvNQzf35/1C7xtrMFJVZuQXkdKtI9/LSW1+QCuwYDDGhJT7rksjMT4maGcN+Vv28UXZER7LzSQmyp23aAsGY0xIie8QxSPDBvCRp5JPSyvdLuecNDR4ZwvpPeL5zpVNrx7UdiwYjDEh596h/ejVpQMzlhYRTF/J//umPXy19xiTR2YSFene27MFgzEm5MRGRzJxeAZrtx9kVfEBt8sJSH2DMjO/iMyenbj98r6u1mLBYIwJSd+7JpXkrh15Oj84Zg1/3VhOScUJpuRlERkhrtZiwWCMCUkdoiJ5dEQGn+86zPKt+90u56xq6xuYtbyY7D5dGD2ot9vlWDAYY0LXd69OoV9iHDPyi2hoaL+zhsUbythReZKpeVlEuDxbAAsGY0wIi46MYFJuJlv2HOW9zXvdLsev6rp6nl3u4YrUruRe0tPtcgALBmNMiBs7OJkBSfHMyC+ivh3OGhau896adFpeFt47IrvPgsEYE9IiI4QpeVkU7z/OO1/sdrucRqpq63luhYdr0rpxU2YPt8v5JwsGY0zI+9alfbi4d2eeWVZMXX2D2+X802uf7mD/sWqmjRrYbmYLYMFgjAkDERHC1Lwsth04weLPmt6Z2B0nqut4cWUJN2QkMrR/otvlNGLBYIwJC3nZvbg8JYFnlxdTU+f+rGH+J9s5cLyGqXkD3S7lGywYjDFhQcR7rqHs0CkWFuxytZajVbW8tLKU4QOTuLpfN1dr8SegYBCR0SJSKCIeEZnuZ3kHEXnTWb5GRNJ8lj3utBeKyK1O20Dnfs6n/xwVkcnOsu4iki8ixc5/29+rZowJSsOyvG/Ez6/wUFVb71odr6zexpFTte1ytgABBIOIRAKzgduAbGC8iGQ36fYgcEhVM4CZwJPO2GxgHDAIGA3MEZFIVS1U1cGqOhi4GjgJvO2sazqwXFUzgeXOc2OMuWAiwrS8LPYereJPa3a6UsPhkzXMW7WNWwf14rKUBFdqaE4gM4YhgEdVS1W1BlgAjG3SZyww33m8CMgV7yn2scACVa1W1W2Ax1mfr1ygRFV3+FnXfODOc9khY4w5m+szenBd/0TmfFDCqZq2nzX8flUpx2vqmJKX1ebbDlQgwZAM+B6QK3Pa/PZR1TrgCJAY4NhxwBs+z3up6h7n8V6gl7+iROQhESkQkYKKiooAdsMYY7ymjcriwPFq/vjJ9jbdbuXxal79aDvfvqwPF/fu0qbbPheunnwWkRhgDPCWv+XqvSSi358qqupcVc1R1ZykpKRWrNIYE2py0rpzc1YSL64s4Xh1XZtt98WVJVTV1jN5ZPudLUBgwVAO+N54NMVp89tHRKKABKAygLG3ARtUdZ9P2z4R6eOsqw/Qvi+LaIwJStPysjh0spZXV29rk+3tO1rFHz/ZwZ1XJpPRs1ObbPN8BRIM64BMEUl3PuGPA5Y06bMEuM95fBewwvm0vwQY53xrKR3IBNb6jBtP48NITdd1H/DXQHfGGGMCdUVqV0Ze0ou5q0o5crK21bc3530P9Q3KpNzMVt/WhWo2GJxzBhOB94CtwEJV3SwiT4jIGKfbPCBRRDzAVJxvEqnqZmAhsAV4F5igqvUAIhIP5AGLm2zyv4E8ESkGRjrPjTGmxU3Ny+JYVR0vry5t1e2UHz7FG2t3cXdOCv0S41t1Wy1BguHORs3JycnRgoICt8swxgShCa9v4IPC/az69Qi6x8e0yjYeX/wFf15fzvu/HEZy146tso3zISLrVTWnabv98tkYE9Ymj8zkZG09L60saZX176w8yVsFZYwfktquQuFsLBiMMWEts1dn7hyczPxPtrP/WFWLr3/W8mIiI4QJwzNafN2txYLBGBP2JuVmUluvzHm/ZWcNnv3HefuzMn44tB89u8S26LpbkwWDMSbspfWI566rUvjTmp3sOXKqxdY7a3kxsdGRPDxsQIutsy1YMBhjDPBobgaK8vwKT4us76u9R/nfz3dz//Vp9OjUoUXW2VYsGIwxBkjpFsc916Ty5rpd7Dp48oLXNzO/iM4donjo5v4tUF3bsmAwxhjHxOGZREQIzy4vvqD1fFl2hPc27+PBm9LpGtc6X4FtTRYMxhjj6J0Qy73X9uPPG8oorTh+3uuZkV9IQsdoHrgxvQWrazsWDMYY4+ORYQPoEBXJrPOcNazfcYj3Cyv42S396RIb3cLVtQ0LBmOM8ZHUuQP3XZ/Gks93U7Tv2DmPn5FfSGJ8DPddl9byxbURCwZjjGniZzf3Jz4mipn5Rec07tPSSj7yVPLIsAHEd4hqpepanwWDMcY00S0+hgduTOcfm/ayqfxIQGNUlRlLi+jVpQP3Du3XyhW2LgsGY4zx48Eb0+kSG/isYVXxAdZuP8iE4RnERke2cnWty4LBGGP8SOgYzc9uGcDyr/bz2c5DZ+2rqjydX0Ry147cc03qWfsGAwsGY4w5g/uvT6N7fAwzmpk1rPhqP5/vOsyjIzLoEBXcswWwYDDGmDOK7xDFw7f09x4m2nbQb5+GBuXppUX0S4zju1entHGFrcOCwRhjzuKHQ9NI6tyBp5YW4u/GZu9t3suWPUeZlJtJdGRovKWGxl4YY0wr6RgTyYRhA1i77SAfeSobLatvUGbkFzEgKZ6xg5NdqrDlBRQMIjJaRApFxCMi0/0s7yAibzrL14hIms+yx532QhG51ae9q4gsEpGvRGSriFzntA8WkU9FZKOIFIjIkAvfTWOMOX/jr72IvgmxPJ3feNbwzhe7Kd5/nCl5WURGiIsVtqxmg0FEIoHZwG1ANjBeRLKbdHsQOKSqGcBM4ElnbDYwDhgEjAbmOOsDmAW8q6oXA1cAW5323wL/oaqDgd84z40xxjUdoiKZOCKTz3Ye5oPCCgDq6ht4ZlkxF/fuzLcu7eNyhS0rkBnDEMCjqqWqWgMsAMY26TMWmO88XgTkiog47QtUtVpVtwEeYIiIJAA3A/MAVLVGVQ874xXo4jxOAHaf364ZY0zLuTsnhdTuHf85a1j8WTnbDpxgSl4WESE0W4DAgiEZ2OXzvMxp89tHVeuAI0DiWcamAxXAqyLymYi8LCLxTp/JwO9EZBfwFPC4v6JE5CHnUFNBRUVFALthjDHnLzoygkm5WWwqP8o7X+zh2eXFXJacwKjsXm6X1uLcOvkcBVwFvKCqVwIngNPnLh4BpqhqKjAFZ1bRlKrOVdUcVc1JSkpqi5qNMWHuzsF96d8jnl+89Tllh04xdVQW3oMjoSWQYCgHfH/Kl+K0+e0jIlF4DwFVnmVsGVCmqmuc9kV4gwLgPmCx8/gtvIeyjDHGdVGREUzOy6K6roGr+3VjWFZofigNJBjWAZkiki4iMXhPJi9p0mcJ3jd0gLuAFeo9db8EGOd8aykdyATWqupeYJeIDHTG5AJbnMe7gVucxyOAC7uVkjHGtKDbL+vDI8MG8J9jLw3J2QJ4D+mclarWichE4D0gEnhFVTeLyBNAgaouwXu4539ExAMcxBseOP0W4n3TrwMmqGq9s+pHgdedsCkFfuy0/xSY5cw8qoCHWmhfjTHmgkVECL8efbHbZbQq8fdLvmCTk5OjBQUFbpdhjDFBRUTWq2pO03b75bMxxphGLBiMMcY0YsFgjDGmEQsGY4wxjVgwGGOMacSCwRhjTCMWDMYYYxoJid8xiEgFsOM8h/cADrRgOcHOXo+v2WvRmL0ejYXC69FPVb9xXY+QCIYLISIF/n7gEa7s9fiavRaN2evRWCi/HnYoyRhjTCMWDMYYYxqxYIC5bhfQztjr8TV7LRqz16OxkH09wv4cgzHGmMZsxmCMMaYRCwZjjDGNhHUwiMhoESkUEY+ITG9+RGgSkVQReV9EtojIZhGZ5HZN7YGIRIrIZyLyjtu1uE1EuorIIhH5SkS2ish1btfkFhGZ4vw72SQib4hIrNs1tbSwDQYRiQRmA7cB2cB4Ecl2tyrX1AHTVDUbGApMCOPXwtckYKvbRbQTs4B3VfVi4ArC9HURkWTgMSBHVS/Fe1fLce5W1fLCNhiAIYBHVUtVtQZYAIx1uSZXqOoeVd3gPD6G9x99srtVuUtEUoBvAy+7XYvbRCQBuBnvLXxR1RpVPexuVa6KAjo6tx+Ow3uf+pASzsGQDOzyeV5GmL8ZAohIGnAlsMbdSlz3DPAroMHtQtqBdKACeNU5tPayiMS7XZQbVLUceArYCewBjqjqUnerannhHAymCRHpBPwZmKyqR92uxy0icjuwX1XXu11LOxEFXAW8oKpXAieAsDwnJyLd8B5ZSAf6AvEicq+7VbW8cA6GciDV53mK0xaWRCQabyi8rqqL3a7HZTcAY0RkO95DjCNE5DV3S3JVGVCmqqdnkYvwBkU4GglsU9UKVa0FFgPXu1xTiwvnYFgHZIpIuojE4D2BtMTlmlwhIoL3+PFWVZ3hdj1uU9XHVTVFVdPw/r1Yoaoh96kwUKq6F9glIgOdplxgi4sluWknMFRE4px/N7mE4In4KLcLcIuq1onIROA9vN8seEVVN7tclltuAH4IfCkiG522f1XVv7tYk2lfHgVedz5ElQI/drkeV6jqGhFZBGzA+22+zwjBS2PYJTGMMcY0Es6HkowxxvhhwWCMMaYRCwZjjDGNWDAYY4xpxILBGGNMIxYMxhhjGrFgMMYY08j/B7ba9WGoawxKAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","\n","# Plot history: MAE\n","plt.plot(history.history['loss'], label='Loss (training data)')\n","plt.plot(history.history['val_loss'], label='Loss (validation data)')\n","plt.title('AutoEncoder loss function')\n","plt.ylabel('MAE value')\n","plt.xlabel('No. epoch')\n","plt.legend(loc=\"upper left\")\n","plt.show()"],"id":"W05J5bchuWE9"},{"cell_type":"code","execution_count":null,"metadata":{"id":"cQP7dWOYuQeF"},"outputs":[],"source":["#save model\n","autoencoder.save(f'{ROOT}/MyDrive/autoencoder/saved_models/autoencoder_Dense_only')"],"id":"cQP7dWOYuQeF"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5tLdSq8muIOL"},"outputs":[],"source":["!path=drive/MyDrive/\"Github Repos\"/"],"id":"5tLdSq8muIOL"}],"metadata":{"colab":{"collapsed_sections":[],"name":"autoencoder.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":5}