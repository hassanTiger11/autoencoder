{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a0c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This file uses the experimental tool published by tensorflow to load\n",
    "tiff files\n",
    "\n",
    "I expect the subset ot look like:\n",
    "foldername:\n",
    "        label1:\n",
    "            img1\n",
    "            img2\n",
    "            img3 \n",
    "            ...\n",
    "        ...\n",
    "\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow_io as tfio\n",
    "import os\n",
    "\n",
    "from load_tiff import process_path\n",
    "\n",
    "\n",
    "class process_tiff_img_set():\n",
    "    def __init__(self, ds_folder_name):\n",
    "        \n",
    "        self.folder = ds_folder_name\n",
    "        self.df =  self.create_df()\n",
    "        #self.ds = self.load_from_df()\n",
    "        self.ds = self.df\n",
    "\n",
    "       \n",
    "\n",
    "    def create_df(self):\n",
    "        '''\n",
    "        This function creates a dataframe with all labels and \n",
    "        images file paths\n",
    "        I will use later to store numpy arrays\n",
    "        '''\n",
    "        ds = {}\n",
    "        DS_PATH = os.path.join(os.getcwd(), self.folder)\n",
    "        labels = os.listdir(DS_PATH)\n",
    "        for lbl in labels:\n",
    "            cwd = os.path.join(DS_PATH, lbl)\n",
    "            if(not os.path.isdir(cwd)):\n",
    "                print(f'{cwd} is not a directory. Will not be in dict')\n",
    "                continue\n",
    "            images = os.listdir(cwd)\n",
    "            for img in images:\n",
    "                #convert to numpy matrix here\n",
    "                path = os.path.join(cwd, img)\n",
    "                img_np = process_path(path) #Tensor \n",
    "                if(lbl in ds):\n",
    "                    #print(f'#ds[{lbl} = [..., {os.path.join(cwd, img)}]')\n",
    "                    \n",
    "                    ds[lbl].append(img_np)\n",
    "                else:\n",
    "                    #print(f'*ds[{lbl} = [{os.path.join(cwd, img)}]]')\n",
    "                    ds[lbl] = []\n",
    "                    ds[lbl].append(img_np)\n",
    "        df = pd.DataFrame.from_dict(ds)\n",
    "        df.to_csv('ds.csv')\n",
    "        return df\n",
    "        \n",
    "    def get_dataframe(self):\n",
    "        '''Create a datrame from json file'''\n",
    "        file = open('ds.json', 'r')\n",
    "        df = pd.DataFrame(json.load(file))\n",
    "        file.close()\n",
    "        return df\n",
    "\n",
    "    def decode_img(self, img):\n",
    "\n",
    "        \n",
    "        #print(f'decoding ... ')\n",
    "        img = tfio.experimental.image.decode_tiff(img, index=0, name=None)\n",
    "\n",
    "        # resize the image to the desired size\n",
    "        return tf.image.resize(img, [256, 256])\n",
    "\n",
    "\n",
    "    def process_path(self, file_path):\n",
    "\n",
    "        # load the raw data from the file as a string\n",
    "        #print(f'reading {file_path}')\n",
    "        img = tf.io.read_file(file_path)\n",
    "        img = self.decode_img(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "    def load_from_df(self):\n",
    "        '''\n",
    "        This function loads a tensorflow dataset from pandas dataframe\n",
    "        WARNINGL: This is for expermentation, edit code to automize\n",
    "        '''\n",
    "        df = self.df\n",
    "        if(df.empty):\n",
    "            #print(f'df is empty, loading existing df')\n",
    "            df = pd.read_csv('ds.csv')\n",
    "        self.ds = {}\n",
    "        for date in df:\n",
    "            for i, img in enumerate(date):\n",
    "                tensor = tf.convert_to_tensor(img)\n",
    "                if(date not in self.ds):\n",
    "                    self.ds[date] = []\n",
    "                self.ds[date].append(tensor)\n",
    "        pd.DataFrame(self.ds).to_csv('processed_ds.csv')\n",
    "        return self.ds\n",
    "\n",
    "    def get_tensor(self):\n",
    "        return pd.DataFrame(self.ds)\n",
    "    def get_dataframe(self):\n",
    "        return self.df\n",
    "\n",
    "    def __str__(self):\n",
    "        obj_str = \"\"\n",
    "        for i, obj in enumerate(self.ds):\n",
    "            obj_str += f'{i}: {str(obj)},\\n'\n",
    "        return f'<process_tiff_img_set>:\\n{obj_str}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77b2c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This file is influeced by Tensorflow tutorial\n",
    "More edits will be applied to it\n",
    "\n",
    "This file contains the implemetation of the neural networks\n",
    "For now it is very simple\n",
    "Encoder: Flatten -> Dense\n",
    "Decoder: Dense- ->\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from load_imgs import load_dataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "class Autoencoder(Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim   \n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(latent_dim, activation='relu'),\n",
    "    ])\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(784, activation='sigmoid'),\n",
    "      layers.Reshape((28, 28))\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "102b68fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ualguest/dev/autoencoder/./subset/.DS_Store is not a directory. Will not be in dict\n",
      "reading /Users/ualguest/dev/autoencoder/./subset/2020-06-23__10-36-48-868/2020-06-23__10-36-48-868___0901___BTx_623.tif\n",
      "decoding ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TIFFReadDirectory: Warning, Unknown field with tag 42113 (0xa481) encountered.\n",
      "TIFFReadDirectory: Warning, Unknown field with tag 42113 (0xa481) encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /Users/ualguest/dev/autoencoder/./subset/2020-06-23__10-36-48-868/2020-06-23__10-36-48-868___0931___PI_678004.tif\n",
      "decoding ... \n",
      "reading /Users/ualguest/dev/autoencoder/./subset/2020-06-23__10-36-48-868/2020-06-23__10-36-48-868___0729___PI_678040.tif\n",
      "decoding ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TIFFReadDirectory: Warning, Unknown field with tag 42113 (0xa481) encountered.\n",
      "TIFFReadDirectory: Warning, Unknown field with tag 42113 (0xa481) encountered.\n",
      "TIFFReadDirectory: Warning, Unknown field with tag 42113 (0xa481) encountered.\n",
      "TIFFReadDirectory: Warning, Unknown field with tag 42113 (0xa481) encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /Users/ualguest/dev/autoencoder/./subset/2020-06-23__10-36-48-868/2020-06-23__10-36-48-868___0801___BTx_623.tif\n",
      "decoding ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TIFFReadDirectory: Warning, Unknown field with tag 42113 (0xa481) encountered.\n",
      "TIFFReadDirectory: Warning, Unknown field with tag 42113 (0xa481) encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /Users/ualguest/dev/autoencoder/./subset/2020-06-23__10-36-48-868/2020-06-23__10-36-48-868___0701___BTx_623.tif\n",
      "decoding ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TIFFReadDirectory: Warning, Unknown field with tag 42113 (0xa481) encountered.\n",
      "TIFFReadDirectory: Warning, Unknown field with tag 42113 (0xa481) encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /Users/ualguest/dev/autoencoder/./subset/2020-06-23__10-36-48-868/2020-06-23__10-36-48-868___0726___PI_677994.tif\n",
      "decoding ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TIFFReadDirectory: Warning, Unknown field with tag 42113 (0xa481) encountered.\n",
      "TIFFReadDirectory: Warning, Unknown field with tag 42113 (0xa481) encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /Users/ualguest/dev/autoencoder/./subset/2020-06-23__10-36-48-868/2020-06-23__10-36-48-868___0725___PI_678118.tif\n",
      "decoding ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TIFFReadDirectory: Warning, Unknown field with tag 42113 (0xa481) encountered.\n",
      "TIFFReadDirectory: Warning, Unknown field with tag 42113 (0xa481) encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor shape: (7, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type tensorflow.python.framework.ops.EagerTensor).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m Autoencoder(\u001b[38;5;241m64\u001b[39m) \n\u001b[1;32m     13\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39mlosses\u001b[38;5;241m.\u001b[39mMeanSquaredError())\n\u001b[0;32m---> 15\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_models/autoencoder_0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/dev/autoencoder/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/dev/autoencoder/.venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type tensorflow.python.framework.ops.EagerTensor)."
     ]
    }
   ],
   "source": [
    "  \n",
    "from autoencoder import *\n",
    "from process_tiff_img_set import process_tiff_img_set\n",
    "\n",
    "ds = process_tiff_img_set(\"./subset\")\n",
    "ds = ds.get_tensor()\n",
    "print(f'tensor shape: {ds.shape}')\n",
    "#print(f'{ds}')\n",
    "\n",
    "\n",
    "\n",
    "autoencoder = Autoencoder(64) \n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "\n",
    "autoencoder.fit(ds, ds,\n",
    "                epochs=1,\n",
    "                shuffle=True,\n",
    "                validation_data=(ds, ds), verbose='auto')\n",
    "autoencoder.save('saved_models/autoencoder_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25a86a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
